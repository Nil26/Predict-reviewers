{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"leading_reviewer_data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "reviewer_path_list = glob(data_path+\"*/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_IS_WINDOW = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only use 10 reviews for each reviewer (pick out the 10 largest size of reviews)\n",
    "reviewers = []\n",
    "reviewers_review = []\n",
    "reviewers_literature = []\n",
    "for reviewer_path in reviewer_path_list:\n",
    "    if SYSTEM_IS_WINDOW:\n",
    "        reviewers.append(re.search(r'leading_reviewer_data\\\\([a-zA-Z_-]*)\\\\',reviewer_path).group(1))\n",
    "    else:\n",
    "        reviewers.append(re.search(r'leading_reviewer_data/([a-zA-Z_-]*)/',reviewer_path).group(1))\n",
    "    current_reviewer_review = [f for f in os.listdir(reviewer_path) if '.txt' in f]\n",
    "    # select the 10 largest size of reviews\n",
    "    current_selected_review_index = np.argsort([os.stat(reviewer_path+f).st_size for f in os.listdir(reviewer_path) if '.txt' in f])[::-1][:10]\n",
    "    current_reviewer_review_selected = list(np.array(current_reviewer_review))\n",
    "    # get the review texts\n",
    "    review_texts = []\n",
    "    for nm in current_reviewer_review_selected:\n",
    "        with open(reviewer_path+nm, encoding=\"utf8\") as f:\n",
    "            text_to_append = f.read().replace('\\n',' ')\n",
    "            review_texts.append(text_to_append)\n",
    "    reviewers_review.append(review_texts)\n",
    "    \n",
    "    if SYSTEM_IS_WINDOW:\n",
    "        current_reviewer_literature = [f for f in os.listdir(reviewer_path+\"training_data\\\\\") if '.txt' in f]\n",
    "    else:\n",
    "        current_reviewer_literature = [f for f in os.listdir(reviewer_path+\"training_data/\") if '.txt' in f]\n",
    "    # get the literature texts\n",
    "    literature_texts = []\n",
    "    for nm in current_reviewer_literature:\n",
    "        if SYSTEM_IS_WINDOW:\n",
    "            text_nm = reviewer_path+\"training_data\\\\\"+nm\n",
    "        else:\n",
    "            text_nm = reviewer_path+\"training_data/\"+nm\n",
    "        with open(text_nm, encoding=\"utf8\") as f:\n",
    "            text_to_append = f.read().replace('\\n',' ')\n",
    "            literature_texts.append(text_to_append)\n",
    "    reviewers_literature.append(literature_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build training set, development set and test set\n",
    "## Randomly picking the test data from the whole dataset\n",
    "total: 25 reviewers\n",
    "\n",
    "each reviewer has 10 reviews and 10 literatures.\n",
    "\n",
    "Test set: half of the reviews (each reviewer has 5 reviews)\n",
    "\n",
    "Development set: the other half of the reviews\n",
    "\n",
    "Training set: all the literatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(100)\n",
    "dev_set = []\n",
    "test_set = []\n",
    "for reviewer in reviewers_review:\n",
    "    # copy() is important here, or the reviewers_review will be shuffled\n",
    "    reviewer_cp = reviewer.copy()\n",
    "    np.random.shuffle(reviewer_cp)\n",
    "    dev_set.append(reviewer_cp[:5])\n",
    "    test_set.append(reviewer_cp[5:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from scipy.cluster.vq import whiten\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "sentence_tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag of words feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "bag of words feature needs to build the corpus from review data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_review_texts = [' '.join(sublib) for sublib in reviewers_review]\n",
    "all_review_texts = ' '.join(all_review_texts)\n",
    "all_tokens = nltk.word_tokenize(all_review_texts)\n",
    "\n",
    "# word_to_ix maps each word in the vocab to a unique integer, which will be its index into the Bag of words vector\n",
    "word_to_ix = {}\n",
    "for word in all_tokens:\n",
    "    if word not in word_to_ix:\n",
    "        word_to_ix[word] = len(word_to_ix)\n",
    "        \n",
    "VOCAB_SIZE = len(word_to_ix)\n",
    "\n",
    "NUM_TOP_WORDS = 1000\n",
    "# get most common words in the whole review set\n",
    "fdist = nltk.FreqDist(all_tokens)\n",
    "vocab_top = fdist.most_common(NUM_TOP_WORDS)\n",
    "vocab_selected = [word_to_ix[voc[0]] for voc in vocab_top]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the input_text can only be one literature\n",
    "def BagOfWords(input_text, word_to_ix, vocab_selected):\n",
    "    \"\"\"\n",
    "    Compute the bag of words feature vectors, based on the most common words\n",
    "     in reviews\n",
    "    \"\"\"\n",
    "    vec = torch.zeros(len(word_to_ix))\n",
    "    tokens = nltk.word_tokenize(input_text)\n",
    "    for word in tokens:\n",
    "        if word in word_to_ix:\n",
    "            vec[word_to_ix[word]] += 1\n",
    "    # the bag of word vector\n",
    "    vec = vec.view(1, -1)\n",
    "    # the bow vector for the selected top words\n",
    "    fvs_bow = torch.index_select(vec,1,torch.tensor(vocab_selected))\n",
    "    fvs_bow /= torch.sum(vec)\n",
    "    return fvs_bow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag of characters features (n-gram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "GRAM_N = 3\n",
    "\n",
    "import nltk\n",
    "from nltk.util import ngrams\n",
    "tokenizer_with_tail_pukt = nltk.tokenize.RegexpTokenizer(r'[a-zA-Z0-9-.()\\[\\]{}]+[,.:?!\\\"\\']?')\n",
    "\n",
    "def NGramCharacter(input_text,GRAM_N):\n",
    "    all_tokens = tokenizer_with_tail_pukt.tokenize(input_text)\n",
    "    N_gram = []\n",
    "    for token in all_tokens:\n",
    "        grams = list(ngrams(token,GRAM_N))\n",
    "        for gm in grams:\n",
    "            N_gram.append(''.join(gm))\n",
    "    return N_gram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build N-gram character vocabulary from reivews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_review_texts = [' '.join(sublib) for sublib in reviewers_review]\n",
    "all_review_texts = ' '.join(all_review_texts)\n",
    "N_gram_char = NGramCharacter(all_review_texts,GRAM_N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "559367"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(N_gram_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ngram_to_ix maps each ngram in the vocab to a unique integer, which will be its index into the Bag of characters vector\n",
    "ngram_to_ix = {}\n",
    "for ngram in N_gram_char:\n",
    "    if ngram not in ngram_to_ix:\n",
    "        ngram_to_ix[ngram] = len(ngram_to_ix)\n",
    "        \n",
    "VOCAB_CHAR_SIZE = len(ngram_to_ix)\n",
    "\n",
    "NUM_TOP_NGRAMS = 1000\n",
    "# get most common ngrams in the whole review set\n",
    "fdist = nltk.FreqDist(N_gram_char)\n",
    "vocab_char_top = fdist.most_common(NUM_TOP_NGRAMS)\n",
    "vocab_char_selected = [ngram_to_ix[voc[0]] for voc in vocab_char_top]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the input_text can only be one literature\n",
    "def BagOfCharacters(input_text, ngram_to_ix, vocab_char_selected):\n",
    "    \"\"\"\n",
    "    Compute the bag of character feature vectors, based on the most common ngrams\n",
    "     in reviews\n",
    "    \"\"\"\n",
    "    GRAM_N = len(list(ngram_to_ix.keys())[0])\n",
    "    \n",
    "    vec = torch.zeros(len(ngram_to_ix))\n",
    "    N_gram_char = NGramCharacter(input_text,GRAM_N)\n",
    "    \n",
    "    for ngram in N_gram_char:\n",
    "        if ngram in ngram_to_ix:\n",
    "            vec[ngram_to_ix[ngram]] += 1\n",
    "    # the bag of chars vector\n",
    "    vec = vec.view(1, -1)\n",
    "    # the boc vector for the selected top chars\n",
    "    fvs_boc = torch.index_select(vec,1,torch.tensor(vocab_char_selected))\n",
    "    fvs_boc /= torch.sum(vec)\n",
    "    return fvs_boc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Syntactic features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagdict = nltk.data.load('help/tagsets/upenn_tagset.pickle')\n",
    "pos_list = list(tagdict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SyntacticFeatures(reviews_texts, pos_list):\n",
    "    \"\"\"\n",
    "    Extract feature vector for part of speech frequencies\n",
    "    \"\"\"\n",
    "    # get part of speech for each token in each review\n",
    "    def token_to_pos(ch):\n",
    "        tokens = nltk.word_tokenize(ch)\n",
    "        return [p[1] for p in nltk.pos_tag(tokens)]\n",
    "    review_pos = [token_to_pos(ch) for ch in reviews_texts]\n",
    " \n",
    "    # count frequencies for all POS types\n",
    "    fvs_syntax = np.array([[ch.count(pos) for pos in pos_list] for ch in review_pos]).astype(np.float64)\n",
    " \n",
    "    # normalise by dividing each row by number of tokens in the review\n",
    "    fvs_syntax /= np.c_[np.array([len(ch) for ch in review_pos])]\n",
    "    \n",
    "    return fvs_syntax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline: logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "\n",
    "torch.manual_seed(100)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "fvs_boc_train = np.array([], dtype=np.int64).reshape(0,NUM_TOP_NGRAMS)\n",
    "fvs_bow_train = np.array([], dtype=np.int64).reshape(0,NUM_TOP_WORDS)\n",
    "fvs_syntax_train = np.array([], dtype=np.int64).reshape(0,len(pos_list))\n",
    "true_label_train = np.array([], dtype=np.int64).reshape(0,1)\n",
    "for lit in np.arange(len(reviewers_literature)):\n",
    "    # bag of words\n",
    "    for per_lit in reviewers_literature[lit]:\n",
    "        fvs_bow_train_cur = BagOfWords(per_lit, word_to_ix, vocab_selected)\n",
    "        fvs_bow_train = np.concatenate((fvs_bow_train,fvs_bow_train_cur))\n",
    "    # bag of chars (n-grams)\n",
    "    for per_lit in reviewers_literature[lit]:\n",
    "        fvs_boc_train_cur = BagOfCharacters(per_lit, ngram_to_ix, vocab_char_selected)\n",
    "        fvs_boc_train = np.concatenate((fvs_boc_train,fvs_boc_train_cur))\n",
    "    # syntax\n",
    "    fvs_syntax_train_cur = SyntacticFeatures(reviewers_literature[lit], pos_list)\n",
    "    fvs_syntax_train = np.concatenate((fvs_syntax_train,fvs_syntax_train_cur))\n",
    "    # label\n",
    "    true_label_train = np.concatenate((true_label_train, lit*np.ones(( len(reviewers_literature[lit]) ,1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "fvs_boc_train = sklearn.preprocessing.scale(fvs_boc_train)\n",
    "fvs_bow_train = sklearn.preprocessing.scale(fvs_bow_train)\n",
    "fvs_syntax_train = sklearn.preprocessing.scale(fvs_syntax_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "fvs_train = np.concatenate((fvs_bow_train,fvs_syntax_train,fvs_boc_train),axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LRClassifier(nn.Module):  # inheriting from nn.Module!\n",
    "\n",
    "    def __init__(self, input_size, num_labels):\n",
    "        # calls the init function of nn.Module.  Dont get confused by syntax,\n",
    "        # just always do it in an nn.Module\n",
    "        super(LRClassifier, self).__init__()\n",
    "\n",
    "        # Define the parameters that you will need.  In this case, we need A and b,\n",
    "        # the parameters of the affine mapping.\n",
    "        # Torch defines nn.Linear(), which provides the affine map.\n",
    "        # Make sure you understand why the input dimension is fvs_dim\n",
    "        # and the output is num_labels!\n",
    "        self.linear = nn.Linear(input_size, num_labels)\n",
    "\n",
    "        # NOTE! The non-linearity log softmax does not have parameters! So we don't need\n",
    "        # to worry about that here\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Pass the input through the linear layer,\n",
    "        # then pass that through log_softmax.\n",
    "        # Many non-linearities and other functions are in torch.nn.functional\n",
    "        out = self.linear(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1/1], Loss: 3.3435\n"
     ]
    }
   ],
   "source": [
    "NUM_LABELS = len(reviewers_literature)\n",
    "INPUT_SIZE = fvs_train.shape[1]\n",
    "input_vector = torch.from_numpy(fvs_train)\n",
    "input_vector = input_vector.float()\n",
    "input_vector = input_vector.to(device)\n",
    "labels = torch.from_numpy(true_label_train)\n",
    "labels = labels.view(-1)\n",
    "labels = labels.long()\n",
    "labels = labels.to(device)\n",
    "model = LRClassifier(INPUT_SIZE, NUM_LABELS)\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "num_epochs = 1\n",
    "\n",
    "# Training the Model\n",
    "for epoch in range(num_epochs):    \n",
    "    # Forward + Backward + Optimize\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(input_vector)\n",
    "    loss = criterion(outputs, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "        \n",
    "    if epoch % 1 == 0:\n",
    "        print ('Epoch: [%d/%d], Loss: %.4f' %(epoch+1, num_epochs, loss.data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score use training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on the 251 training sets: 99.000000 %\n"
     ]
    }
   ],
   "source": [
    "# Test the Model\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "outputs = model(input_vector)\n",
    "_, predicted = torch.max(outputs.data, 1)\n",
    "total += labels.size(0)\n",
    "correct += (predicted == labels).sum()\n",
    "    \n",
    "print('Accuracy of the model on the %d training sets: %f %%' % (total , 100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### development data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "fvs_boc_dev = np.array([], dtype=np.int64).reshape(0,NUM_TOP_NGRAMS)\n",
    "fvs_bow_dev = np.array([], dtype=np.int64).reshape(0,NUM_TOP_WORDS)\n",
    "fvs_syntax_dev = np.array([], dtype=np.int64).reshape(0,len(pos_list))\n",
    "true_label_dev = np.array([], dtype=np.int64).reshape(0,1)\n",
    "for index in np.arange(len(dev_set)):\n",
    "    # bag of words\n",
    "    for per_review in dev_set[index]:\n",
    "        fvs_bow_dev_cur = BagOfWords(per_review, word_to_ix, vocab_selected)\n",
    "        fvs_bow_dev = np.concatenate((fvs_bow_dev,fvs_bow_dev_cur))\n",
    "    # bag of chars (n-grams)\n",
    "    for per_review in dev_set[index]:\n",
    "        fvs_boc_dev_cur = BagOfCharacters(per_review, ngram_to_ix, vocab_char_selected)\n",
    "        fvs_boc_dev = np.concatenate((fvs_boc_dev,fvs_boc_dev_cur))\n",
    "    # syntax\n",
    "    fvs_syntax_dev_cur = SyntacticFeatures(dev_set[index], pos_list)\n",
    "    fvs_syntax_dev = np.concatenate((fvs_syntax_dev,fvs_syntax_dev_cur))\n",
    "    # label\n",
    "    true_label_dev = np.concatenate((true_label_dev, index*np.ones(( len(dev_set[index]) ,1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "fvs_boc_dev = sklearn.preprocessing.scale(fvs_boc_dev)\n",
    "fvs_bow_dev = sklearn.preprocessing.scale(fvs_bow_dev)\n",
    "fvs_syntax_dev = sklearn.preprocessing.scale(fvs_syntax_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "fvs_dev = np.concatenate((fvs_bow_dev,fvs_syntax_dev,fvs_boc_dev),axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score use dev data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on the 125 development sets: 56.000000 %\n"
     ]
    }
   ],
   "source": [
    "input_vector = torch.from_numpy(fvs_dev)\n",
    "input_vector = input_vector.float()\n",
    "input_vector = input_vector.to(device)\n",
    "labels = torch.from_numpy(true_label_dev)\n",
    "labels = labels.view(-1)\n",
    "labels = labels.long()\n",
    "labels = labels.to(device)\n",
    "\n",
    "# Test the Model\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "outputs = model(input_vector)\n",
    "_, predicted = torch.max(outputs.data, 1)\n",
    "total += labels.size(0)\n",
    "correct += (predicted == labels).sum()\n",
    "    \n",
    "print('Accuracy of the model on the %d development sets: %f %%' % (total , 100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test data and score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "fvs_bow_test = np.array([], dtype=np.int64).reshape(0,NUM_TOP_WORDS)\n",
    "fvs_syntax_test = np.array([], dtype=np.int64).reshape(0,len(pos_list))\n",
    "true_label_test = np.array([], dtype=np.int64).reshape(0,1)\n",
    "for index in np.arange(len(test_set)):\n",
    "    # bag of words\n",
    "    for per_review in test_set[index]:\n",
    "        fvs_bow_test_cur = BagOfWords(per_review, word_to_ix, vocab_selected)\n",
    "        fvs_bow_test = np.concatenate((fvs_bow_test,fvs_bow_test_cur))\n",
    "    # syntax\n",
    "    fvs_syntax_test_cur = SyntacticFeatures(test_set[index], pos_list)\n",
    "    fvs_syntax_test = np.concatenate((fvs_syntax_test,fvs_syntax_test_cur))\n",
    "    # label\n",
    "    true_label_test = np.concatenate((true_label_test, index*np.ones(( len(test_set[index]) ,1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "fvs_test = np.concatenate((fvs_bow_test,fvs_syntax_test),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on the 199 test sets: 25.000000 %\n"
     ]
    }
   ],
   "source": [
    "input_vector = torch.from_numpy(fvs_test)\n",
    "input_vector = input_vector.float()\n",
    "input_vector = input_vector.to(device)\n",
    "labels = torch.from_numpy(true_label_test)\n",
    "labels = labels.view(-1)\n",
    "labels = labels.long()\n",
    "labels = labels.to(device)\n",
    "\n",
    "# Test the Model\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "outputs = model(input_vector)\n",
    "_, predicted = torch.max(outputs.data, 1)\n",
    "total += labels.size(0)\n",
    "correct += (predicted == labels).sum()\n",
    "print('Accuracy of the model on the %d test sets: %f %%' % (total , 100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = svm.LinearSVC(multi_class=\"ovr\",C=0.01)\n",
    "X = fvs_train\n",
    "y = true_label_train.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=0.01, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score use training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on the 251 training sets: 100.000000 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "labels = true_label_train.flatten()\n",
    "\n",
    "predicted = clf.predict(fvs_train)\n",
    "total = labels.size\n",
    "correct = (predicted == labels).sum()\n",
    "print('Accuracy of the model on the %d training sets: %f %%' % (total , 100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score use dev data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on the 125 development sets: 59.200000 %\n"
     ]
    }
   ],
   "source": [
    "# Test the Model\n",
    "correct = 0\n",
    "labels = true_label_dev.flatten()\n",
    "\n",
    "predicted = clf.predict(fvs_dev)\n",
    "total = labels.size\n",
    "correct = (predicted == labels).sum()\n",
    "print('Accuracy of the model on the %d development sets: %f %%' % (total , 100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
