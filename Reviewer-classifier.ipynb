{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"leading_reviewer_data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "reviewer_path_list = glob(data_path+\"*/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import numpy as np\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_IS_WINDOW = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only use 10 reviews for each reviewer (pick out the 10 largest size of reviews)\n",
    "reviewers = []\n",
    "reviewers_review = []\n",
    "reviewers_literature = []\n",
    "reviewers_literature_single_multiple_author_word_count = np.zeros((len(reviewer_path_list),2)) # single first, multiple second\n",
    "reviewer_index = 0\n",
    "for reviewer_path in reviewer_path_list:\n",
    "    if SYSTEM_IS_WINDOW:\n",
    "        reviewers.append(re.search(r'leading_reviewer_data\\\\([a-zA-Z_-]*)\\\\',reviewer_path).group(1))\n",
    "    else:\n",
    "        reviewers.append(re.search(r'leading_reviewer_data/([a-zA-Z_-]*)/',reviewer_path).group(1))\n",
    "    current_reviewer_review = [f for f in os.listdir(reviewer_path) if '.txt' in f]\n",
    "    # select the 10 largest size of reviews\n",
    "    current_selected_review_index = np.argsort([os.stat(reviewer_path+f).st_size for f in os.listdir(reviewer_path) if '.txt' in f])[::-1][:10]\n",
    "    current_reviewer_review_selected = list(np.take(np.array(current_reviewer_review),current_selected_review_index))\n",
    "    # get the review texts\n",
    "    review_texts = []\n",
    "    for nm in current_reviewer_review_selected:\n",
    "        with open(reviewer_path+nm, encoding=\"utf8\") as f:\n",
    "            text_to_append = f.read().replace('\\n',' ')\n",
    "            review_texts.append(text_to_append)\n",
    "    reviewers_review.append(review_texts)\n",
    "    \n",
    "    if SYSTEM_IS_WINDOW:\n",
    "        current_reviewer_literature = [f for f in os.listdir(reviewer_path+\"training_data\\\\\") if '.txt' in f]\n",
    "    else:\n",
    "        current_reviewer_literature = [f for f in os.listdir(reviewer_path+\"training_data/\") if '.txt' in f]\n",
    "    # get the literature texts\n",
    "    literature_texts = []\n",
    "    for nm in current_reviewer_literature:\n",
    "        if SYSTEM_IS_WINDOW:\n",
    "            text_nm = reviewer_path+\"training_data\\\\\"+nm\n",
    "        else:\n",
    "            text_nm = reviewer_path+\"training_data/\"+nm\n",
    "        with open(text_nm, encoding=\"utf8\") as f:\n",
    "            text_to_append = f.read().replace('\\n',' ')\n",
    "            literature_texts.append(text_to_append)\n",
    "        # count the words for single and multiple author literatures\n",
    "        if re.search(r'-M.txt',nm) == None:\n",
    "            # single author literature\n",
    "            wordcount = len(nltk.word_tokenize(text_to_append))\n",
    "            reviewers_literature_single_multiple_author_word_count[reviewer_index][0] += wordcount\n",
    "        else:\n",
    "            # multiple author literature\n",
    "            wordcount = len(nltk.word_tokenize(text_to_append))\n",
    "            reviewers_literature_single_multiple_author_word_count[reviewer_index][1] += wordcount\n",
    "    reviewers_literature.append(literature_texts)\n",
    "    \n",
    "    reviewer_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build training set, development set and test set\n",
    "## Randomly picking the test data from the whole dataset\n",
    "total: 25 reviewers\n",
    "\n",
    "each reviewer has 10 reviews and 10 literatures.\n",
    "\n",
    "Test set: half of the reviews (each reviewer has 5 reviews)\n",
    "\n",
    "Development set: the other half of the reviews\n",
    "\n",
    "Training set: all the literatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(100)\n",
    "dev_set = []\n",
    "test_set = []\n",
    "for reviewer in reviewers_review:\n",
    "    # copy() is important here, or the reviewers_review will be shuffled\n",
    "    reviewer_cp = reviewer.copy()\n",
    "    np.random.shuffle(reviewer_cp)\n",
    "    dev_set.append(reviewer_cp[:5])\n",
    "    test_set.append(reviewer_cp[5:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.cluster.vq import whiten\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "sentence_tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag of words feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "bag of words feature needs to build the corpus from review data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_review_texts = [' '.join(sublib) for sublib in reviewers_review]\n",
    "all_review_texts = ' '.join(all_review_texts)\n",
    "all_tokens = nltk.word_tokenize(all_review_texts)\n",
    "\n",
    "# word_to_ix maps each word in the vocab to a unique integer, which will be its index into the Bag of words vector\n",
    "word_to_ix = {}\n",
    "for word in all_tokens:\n",
    "    if word not in word_to_ix:\n",
    "        word_to_ix[word] = len(word_to_ix)\n",
    "        \n",
    "VOCAB_SIZE = len(word_to_ix)\n",
    "\n",
    "NUM_TOP_WORDS = 500\n",
    "# get most common words in the whole review set\n",
    "fdist = nltk.FreqDist(all_tokens)\n",
    "vocab_top = fdist.most_common(NUM_TOP_WORDS)\n",
    "vocab_selected = [word_to_ix[voc[0]] for voc in vocab_top]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the input_text can only be one literature\n",
    "def BagOfWords(input_text, word_to_ix, vocab_selected):\n",
    "    \"\"\"\n",
    "    Compute the bag of words feature vectors, based on the most common words\n",
    "     in reviews\n",
    "    \"\"\"\n",
    "    vec = torch.zeros(len(word_to_ix))\n",
    "    tokens = nltk.word_tokenize(input_text)\n",
    "    for word in tokens:\n",
    "        if word in word_to_ix:\n",
    "            vec[word_to_ix[word]] += 1\n",
    "    # the bag of word vector\n",
    "    vec = vec.view(1, -1)\n",
    "    # the bow vector for the selected top words\n",
    "    fvs_bow = torch.index_select(vec,1,torch.tensor(vocab_selected))\n",
    "    fvs_bow /= torch.sum(vec)\n",
    "    return fvs_bow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag of characters features (n-gram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "GRAM_N = 3\n",
    "\n",
    "import nltk\n",
    "from nltk.util import ngrams\n",
    "tokenizer_with_tail_pukt = nltk.tokenize.RegexpTokenizer(r'[a-zA-Z0-9-.()\\[\\]{}]+[,.:?!\\\"\\']?')\n",
    "\n",
    "def NGramCharacter(input_text,GRAM_N):\n",
    "    all_tokens = tokenizer_with_tail_pukt.tokenize(input_text)\n",
    "    N_gram = []\n",
    "    for token in all_tokens:\n",
    "        grams = list(ngrams(token,GRAM_N))\n",
    "        for gm in grams:\n",
    "            N_gram.append(''.join(gm))\n",
    "    return N_gram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build N-gram character vocabulary from reivews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_review_texts = [' '.join(sublib) for sublib in reviewers_review]\n",
    "all_review_texts = ' '.join(all_review_texts)\n",
    "N_gram_char = NGramCharacter(all_review_texts,GRAM_N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ngram_to_ix maps each ngram in the vocab to a unique integer, which will be its index into the Bag of characters vector\n",
    "ngram_to_ix = {}\n",
    "for ngram in N_gram_char:\n",
    "    if ngram not in ngram_to_ix:\n",
    "        ngram_to_ix[ngram] = len(ngram_to_ix)\n",
    "        \n",
    "VOCAB_CHAR_SIZE = len(ngram_to_ix)\n",
    "\n",
    "NUM_TOP_NGRAMS = 1000\n",
    "# get most common ngrams in the whole review set\n",
    "fdist = nltk.FreqDist(N_gram_char)\n",
    "vocab_char_top = fdist.most_common(NUM_TOP_NGRAMS)\n",
    "vocab_char_selected = [ngram_to_ix[voc[0]] for voc in vocab_char_top]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the input_text can only be one literature\n",
    "def BagOfCharacters(input_text, ngram_to_ix, vocab_char_selected):\n",
    "    \"\"\"\n",
    "    Compute the bag of character feature vectors, based on the most common ngrams\n",
    "     in reviews\n",
    "    \"\"\"\n",
    "    GRAM_N = len(list(ngram_to_ix.keys())[0])\n",
    "    \n",
    "    vec = torch.zeros(len(ngram_to_ix))\n",
    "    N_gram_char = NGramCharacter(input_text,GRAM_N)\n",
    "    \n",
    "    for ngram in N_gram_char:\n",
    "        if ngram in ngram_to_ix:\n",
    "            vec[ngram_to_ix[ngram]] += 1\n",
    "    # the bag of chars vector\n",
    "    vec = vec.view(1, -1)\n",
    "    # the boc vector for the selected top chars\n",
    "    fvs_boc = torch.index_select(vec,1,torch.tensor(vocab_char_selected))\n",
    "    fvs_boc /= torch.sum(vec)\n",
    "    return fvs_boc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Syntactic features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagdict = nltk.data.load('help/tagsets/upenn_tagset.pickle')\n",
    "pos_list = list(tagdict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SyntacticFeatures(reviews_texts, pos_list):\n",
    "    \"\"\"\n",
    "    Extract feature vector for part of speech frequencies\n",
    "    \"\"\"\n",
    "    # get part of speech for each token in each review\n",
    "    def token_to_pos(ch):\n",
    "        tokens = nltk.word_tokenize(ch)\n",
    "        return [p[1] for p in nltk.pos_tag(tokens)]\n",
    "    review_pos = [token_to_pos(ch) for ch in reviews_texts]\n",
    " \n",
    "    # count frequencies for all POS types\n",
    "    fvs_syntax = np.array([[ch.count(pos) for pos in pos_list] for ch in review_pos]).astype(np.float64)\n",
    " \n",
    "    # normalise by dividing each row by number of tokens in the review\n",
    "    fvs_syntax /= np.c_[np.array([len(ch) for ch in review_pos])]\n",
    "    \n",
    "    return fvs_syntax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## logistic regression (SGD and AdamGrad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "\n",
    "torch.manual_seed(100)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "fvs_boc_train = np.array([], dtype=np.int64).reshape(0,NUM_TOP_NGRAMS)\n",
    "fvs_bow_train = np.array([], dtype=np.int64).reshape(0,NUM_TOP_WORDS)\n",
    "fvs_syntax_train = np.array([], dtype=np.int64).reshape(0,len(pos_list))\n",
    "true_label_train = np.array([], dtype=np.int64).reshape(0,1)\n",
    "for lit in np.arange(len(reviewers_literature)):\n",
    "    # bag of words\n",
    "    for per_lit in reviewers_literature[lit]:\n",
    "        fvs_bow_train_cur = BagOfWords(per_lit, word_to_ix, vocab_selected)\n",
    "        fvs_bow_train = np.concatenate((fvs_bow_train,fvs_bow_train_cur))\n",
    "    # bag of chars (n-grams)\n",
    "    for per_lit in reviewers_literature[lit]:\n",
    "        fvs_boc_train_cur = BagOfCharacters(per_lit, ngram_to_ix, vocab_char_selected)\n",
    "        fvs_boc_train = np.concatenate((fvs_boc_train,fvs_boc_train_cur))\n",
    "    # syntax\n",
    "    fvs_syntax_train_cur = SyntacticFeatures(reviewers_literature[lit], pos_list)\n",
    "    fvs_syntax_train = np.concatenate((fvs_syntax_train,fvs_syntax_train_cur))\n",
    "    # label\n",
    "    true_label_train = np.concatenate((true_label_train, lit*np.ones(( len(reviewers_literature[lit]) ,1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "fvs_boc_train = sklearn.preprocessing.scale(fvs_boc_train)\n",
    "fvs_bow_train = sklearn.preprocessing.scale(fvs_bow_train)\n",
    "fvs_syntax_train = sklearn.preprocessing.scale(fvs_syntax_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "fvs_train = np.concatenate((fvs_bow_train,fvs_syntax_train,fvs_boc_train),axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LRClassifier(nn.Module):  # inheriting from nn.Module!\n",
    "\n",
    "    def __init__(self, input_size, num_labels):\n",
    "        # calls the init function of nn.Module.  Dont get confused by syntax,\n",
    "        # just always do it in an nn.Module\n",
    "        super(LRClassifier, self).__init__()\n",
    "\n",
    "        # Define the parameters that you will need.  In this case, we need A and b,\n",
    "        # the parameters of the affine mapping.\n",
    "        # Torch defines nn.Linear(), which provides the affine map.\n",
    "        # Make sure you understand why the input dimension is fvs_dim\n",
    "        # and the output is num_labels!\n",
    "        self.linear = nn.Linear(input_size, num_labels)\n",
    "\n",
    "        # NOTE! The non-linearity log softmax does not have parameters! So we don't need\n",
    "        # to worry about that here\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Pass the input through the linear layer,\n",
    "        # then pass that through log_softmax.\n",
    "        # Many non-linearities and other functions are in torch.nn.functional\n",
    "        out = self.linear(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1/5000], Loss: 3.2992\n",
      "Epoch: [101/5000], Loss: 0.2006\n",
      "Epoch: [201/5000], Loss: 0.0808\n",
      "Epoch: [301/5000], Loss: 0.0493\n",
      "Epoch: [401/5000], Loss: 0.0353\n",
      "Epoch: [501/5000], Loss: 0.0274\n",
      "Epoch: [601/5000], Loss: 0.0224\n",
      "Epoch: [701/5000], Loss: 0.0190\n",
      "Epoch: [801/5000], Loss: 0.0164\n",
      "Epoch: [901/5000], Loss: 0.0145\n",
      "Epoch: [1001/5000], Loss: 0.0130\n",
      "Epoch: [1101/5000], Loss: 0.0117\n",
      "Epoch: [1201/5000], Loss: 0.0107\n",
      "Epoch: [1301/5000], Loss: 0.0099\n",
      "Epoch: [1401/5000], Loss: 0.0091\n",
      "Epoch: [1501/5000], Loss: 0.0085\n",
      "Epoch: [1601/5000], Loss: 0.0079\n",
      "Epoch: [1701/5000], Loss: 0.0075\n",
      "Epoch: [1801/5000], Loss: 0.0070\n",
      "Epoch: [1901/5000], Loss: 0.0067\n",
      "Epoch: [2001/5000], Loss: 0.0063\n",
      "Epoch: [2101/5000], Loss: 0.0060\n",
      "Epoch: [2201/5000], Loss: 0.0057\n",
      "Epoch: [2301/5000], Loss: 0.0055\n",
      "Epoch: [2401/5000], Loss: 0.0052\n",
      "Epoch: [2501/5000], Loss: 0.0050\n",
      "Epoch: [2601/5000], Loss: 0.0048\n",
      "Epoch: [2701/5000], Loss: 0.0047\n",
      "Epoch: [2801/5000], Loss: 0.0045\n",
      "Epoch: [2901/5000], Loss: 0.0043\n",
      "Epoch: [3001/5000], Loss: 0.0042\n",
      "Epoch: [3101/5000], Loss: 0.0040\n",
      "Epoch: [3201/5000], Loss: 0.0039\n",
      "Epoch: [3301/5000], Loss: 0.0038\n",
      "Epoch: [3401/5000], Loss: 0.0037\n",
      "Epoch: [3501/5000], Loss: 0.0036\n",
      "Epoch: [3601/5000], Loss: 0.0035\n",
      "Epoch: [3701/5000], Loss: 0.0034\n",
      "Epoch: [3801/5000], Loss: 0.0033\n",
      "Epoch: [3901/5000], Loss: 0.0032\n",
      "Epoch: [4001/5000], Loss: 0.0031\n",
      "Epoch: [4101/5000], Loss: 0.0031\n",
      "Epoch: [4201/5000], Loss: 0.0030\n",
      "Epoch: [4301/5000], Loss: 0.0029\n",
      "Epoch: [4401/5000], Loss: 0.0028\n",
      "Epoch: [4501/5000], Loss: 0.0028\n",
      "Epoch: [4601/5000], Loss: 0.0027\n",
      "Epoch: [4701/5000], Loss: 0.0027\n",
      "Epoch: [4801/5000], Loss: 0.0026\n",
      "Epoch: [4901/5000], Loss: 0.0026\n"
     ]
    }
   ],
   "source": [
    "NUM_LABELS = len(reviewers_literature)\n",
    "INPUT_SIZE = fvs_train.shape[1]\n",
    "input_vector = torch.from_numpy(fvs_train)\n",
    "input_vector = input_vector.float()\n",
    "input_vector = input_vector.to(device)\n",
    "labels = torch.from_numpy(true_label_train)\n",
    "labels = labels.view(-1)\n",
    "labels = labels.long()\n",
    "labels = labels.to(device)\n",
    "model = LRClassifier(INPUT_SIZE, NUM_LABELS)\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "num_epochs = 5000\n",
    "\n",
    "# Training the Model\n",
    "for epoch in range(num_epochs):    \n",
    "    # Forward + Backward + Optimize\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(input_vector)\n",
    "    loss = criterion(outputs, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "        \n",
    "    if epoch % 100 == 0:\n",
    "        print ('Epoch: [%d/%d], Loss: %.4f' %(epoch+1, num_epochs, loss.data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score use training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on the 251 training sets: 100.000000 %\n"
     ]
    }
   ],
   "source": [
    "# Test the Model\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "outputs = model(input_vector)\n",
    "_, predicted = torch.max(outputs.data, 1)\n",
    "total += labels.size(0)\n",
    "correct += (predicted == labels).sum()\n",
    "    \n",
    "print('Accuracy of the model on the %d training sets: %f %%' % (total , 100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### development data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "fvs_boc_dev = np.array([], dtype=np.int64).reshape(0,NUM_TOP_NGRAMS)\n",
    "fvs_bow_dev = np.array([], dtype=np.int64).reshape(0,NUM_TOP_WORDS)\n",
    "fvs_syntax_dev = np.array([], dtype=np.int64).reshape(0,len(pos_list))\n",
    "true_label_dev = np.array([], dtype=np.int64).reshape(0,1)\n",
    "for index in np.arange(len(dev_set)):\n",
    "    # bag of words\n",
    "    for per_review in dev_set[index]:\n",
    "        fvs_bow_dev_cur = BagOfWords(per_review, word_to_ix, vocab_selected)\n",
    "        fvs_bow_dev = np.concatenate((fvs_bow_dev,fvs_bow_dev_cur))\n",
    "    # bag of chars (n-grams)\n",
    "    for per_review in dev_set[index]:\n",
    "        fvs_boc_dev_cur = BagOfCharacters(per_review, ngram_to_ix, vocab_char_selected)\n",
    "        fvs_boc_dev = np.concatenate((fvs_boc_dev,fvs_boc_dev_cur))\n",
    "    # syntax\n",
    "    fvs_syntax_dev_cur = SyntacticFeatures(dev_set[index], pos_list)\n",
    "    fvs_syntax_dev = np.concatenate((fvs_syntax_dev,fvs_syntax_dev_cur))\n",
    "    # label\n",
    "    true_label_dev = np.concatenate((true_label_dev, index*np.ones(( len(dev_set[index]) ,1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "fvs_boc_dev = sklearn.preprocessing.scale(fvs_boc_dev)\n",
    "fvs_bow_dev = sklearn.preprocessing.scale(fvs_bow_dev)\n",
    "fvs_syntax_dev = sklearn.preprocessing.scale(fvs_syntax_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "fvs_dev = np.concatenate((fvs_bow_dev,fvs_syntax_dev,fvs_boc_dev),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score use dev data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_vector = torch.from_numpy(fvs_dev)\n",
    "input_vector = input_vector.float()\n",
    "input_vector = input_vector.to(device)\n",
    "labels = torch.from_numpy(true_label_dev)\n",
    "labels = labels.view(-1)\n",
    "labels = labels.long()\n",
    "labels = labels.to(device)\n",
    "\n",
    "# Test the Model\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "outputs = model(input_vector)\n",
    "_, predicted = torch.max(outputs.data, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full training set.\n",
      "The scores are computed on the full validation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.67      0.80      0.73         5\n",
      "         1.0       0.17      0.20      0.18         5\n",
      "         2.0       0.25      0.20      0.22         5\n",
      "         3.0       0.33      0.40      0.36         5\n",
      "         4.0       0.33      0.20      0.25         5\n",
      "         5.0       0.67      0.40      0.50         5\n",
      "         6.0       0.20      0.40      0.27         5\n",
      "         7.0       0.20      0.20      0.20         5\n",
      "         8.0       0.56      1.00      0.71         5\n",
      "         9.0       0.50      0.20      0.29         5\n",
      "        10.0       0.50      0.20      0.29         5\n",
      "        11.0       0.80      0.80      0.80         5\n",
      "        12.0       0.00      0.00      0.00         5\n",
      "        13.0       0.40      0.80      0.53         5\n",
      "        14.0       0.83      1.00      0.91         5\n",
      "        15.0       0.67      0.40      0.50         5\n",
      "        16.0       0.29      0.40      0.33         5\n",
      "        17.0       0.40      0.40      0.40         5\n",
      "        18.0       0.50      0.40      0.44         5\n",
      "        19.0       0.00      0.00      0.00         5\n",
      "        20.0       0.57      0.80      0.67         5\n",
      "        21.0       0.83      1.00      0.91         5\n",
      "        22.0       0.60      0.60      0.60         5\n",
      "        23.0       0.00      0.00      0.00         5\n",
      "        24.0       0.50      0.60      0.55         5\n",
      "\n",
      "   micro avg       0.46      0.46      0.46       125\n",
      "   macro avg       0.43      0.46      0.43       125\n",
      "weighted avg       0.43      0.46      0.43       125\n",
      "\n",
      "\n",
      "The accuracy for the validation set:\n",
      "\n",
      "0.456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhshang/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(\"Detailed classification report:\")\n",
    "print()\n",
    "print(\"The model is trained on the full training set.\")\n",
    "print(\"The scores are computed on the full validation set.\")\n",
    "print()\n",
    "y_true, y_pred = true_label_dev.flatten(), predicted.flatten()\n",
    "print(classification_report(y_true, y_pred))\n",
    "print()\n",
    "acc = accuracy_score(y_true, y_pred)\n",
    "print(\"The accuracy for the validation set:\")\n",
    "print()\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test data and score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "fvs_boc_test = np.array([], dtype=np.int64).reshape(0,NUM_TOP_NGRAMS)\n",
    "fvs_bow_test = np.array([], dtype=np.int64).reshape(0,NUM_TOP_WORDS)\n",
    "fvs_syntax_test = np.array([], dtype=np.int64).reshape(0,len(pos_list))\n",
    "true_label_test = np.array([], dtype=np.int64).reshape(0,1)\n",
    "for index in np.arange(len(test_set)):\n",
    "    # bag of words\n",
    "    for per_review in test_set[index]:\n",
    "        fvs_bow_test_cur = BagOfWords(per_review, word_to_ix, vocab_selected)\n",
    "        fvs_bow_test = np.concatenate((fvs_bow_test,fvs_bow_test_cur))\n",
    "    # bag of chars (n-grams)\n",
    "    for per_review in test_set[index]:\n",
    "        fvs_boc_test_cur = BagOfCharacters(per_review, ngram_to_ix, vocab_char_selected)\n",
    "        fvs_boc_test = np.concatenate((fvs_boc_test,fvs_boc_test_cur))\n",
    "    # syntax\n",
    "    fvs_syntax_test_cur = SyntacticFeatures(test_set[index], pos_list)\n",
    "    fvs_syntax_test = np.concatenate((fvs_syntax_test,fvs_syntax_test_cur))\n",
    "    # label\n",
    "    true_label_test = np.concatenate((true_label_test, index*np.ones(( len(test_set[index]) ,1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "fvs_boc_test = sklearn.preprocessing.scale(fvs_boc_test)\n",
    "fvs_bow_test = sklearn.preprocessing.scale(fvs_bow_test)\n",
    "fvs_syntax_test = sklearn.preprocessing.scale(fvs_syntax_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "fvs_test = np.concatenate((fvs_bow_test,fvs_syntax_test,fvs_boc_test),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_vector = torch.from_numpy(fvs_test)\n",
    "input_vector = input_vector.float()\n",
    "input_vector = input_vector.to(device)\n",
    "labels = torch.from_numpy(true_label_test)\n",
    "labels = labels.view(-1)\n",
    "labels = labels.long()\n",
    "labels = labels.to(device)\n",
    "\n",
    "outputs = model(input_vector)\n",
    "_, predicted = torch.max(outputs.data, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full training set.\n",
      "The scores are computed on the full test set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.40      0.57         5\n",
      "         1.0       0.43      0.60      0.50         5\n",
      "         2.0       0.60      0.60      0.60         5\n",
      "         3.0       0.38      0.60      0.46         5\n",
      "         4.0       0.67      0.40      0.50         5\n",
      "         5.0       0.60      0.60      0.60         5\n",
      "         6.0       0.25      0.20      0.22         5\n",
      "         7.0       0.33      0.40      0.36         5\n",
      "         8.0       0.38      0.60      0.46         5\n",
      "         9.0       0.00      0.00      0.00         5\n",
      "        10.0       1.00      0.60      0.75         5\n",
      "        11.0       0.80      0.80      0.80         5\n",
      "        12.0       1.00      0.20      0.33         5\n",
      "        13.0       0.57      0.80      0.67         5\n",
      "        14.0       0.33      0.40      0.36         5\n",
      "        15.0       0.80      0.80      0.80         5\n",
      "        16.0       0.33      0.20      0.25         5\n",
      "        17.0       0.75      0.60      0.67         5\n",
      "        18.0       0.33      0.20      0.25         5\n",
      "        19.0       0.43      0.60      0.50         5\n",
      "        20.0       0.33      0.60      0.43         5\n",
      "        21.0       1.00      1.00      1.00         5\n",
      "        22.0       0.56      1.00      0.71         5\n",
      "        23.0       0.40      0.40      0.40         5\n",
      "        24.0       1.00      0.40      0.57         5\n",
      "\n",
      "   micro avg       0.52      0.52      0.52       125\n",
      "   macro avg       0.57      0.52      0.51       125\n",
      "weighted avg       0.57      0.52      0.51       125\n",
      "\n",
      "\n",
      "The accuracy for the test set:\n",
      "\n",
      "0.52\n"
     ]
    }
   ],
   "source": [
    "print(\"Detailed classification report:\")\n",
    "print()\n",
    "print(\"The model is trained on the full training set.\")\n",
    "print(\"The scores are computed on the full test set.\")\n",
    "print()\n",
    "y_true, y_pred = true_label_test.flatten(), predicted.flatten()\n",
    "print(classification_report(y_true, y_pred))\n",
    "print()\n",
    "acc = accuracy_score(y_true, y_pred)\n",
    "print(\"The accuracy for the test set:\")\n",
    "print()\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameter estimation using grid search with cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Parameter estimation using grid search with cross-validation\n",
      "============================================================\n",
      "\n",
      "This examples shows how a classifier is optimized by cross-validation,\n",
      "which is done using the :class:`sklearn.model_selection.GridSearchCV` object\n",
      "\n",
      "More details on tools available for model selection can be found in the\n",
      "sections on :ref:`cross_validation` and :ref:`grid_search`.\n",
      "\n",
      "\n",
      "# Tuning hyper-parameters for precision\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhshang/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on training set:\n",
      "\n",
      "{'C': 0.005, 'multi_class': 'ovr'}\n",
      "\n",
      "Grid scores on training set:\n",
      "\n",
      "0.785 (+/-0.129) for {'C': 0.0001, 'multi_class': 'ovr'}\n",
      "0.801 (+/-0.102) for {'C': 0.001, 'multi_class': 'ovr'}\n",
      "0.817 (+/-0.093) for {'C': 0.005, 'multi_class': 'ovr'}\n",
      "0.817 (+/-0.093) for {'C': 0.01, 'multi_class': 'ovr'}\n",
      "0.813 (+/-0.087) for {'C': 0.05, 'multi_class': 'ovr'}\n",
      "\n",
      "# Tuning hyper-parameters for recall\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhshang/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on training set:\n",
      "\n",
      "{'C': 0.005, 'multi_class': 'ovr'}\n",
      "\n",
      "Grid scores on training set:\n",
      "\n",
      "0.785 (+/-0.129) for {'C': 0.0001, 'multi_class': 'ovr'}\n",
      "0.801 (+/-0.102) for {'C': 0.001, 'multi_class': 'ovr'}\n",
      "0.817 (+/-0.093) for {'C': 0.005, 'multi_class': 'ovr'}\n",
      "0.817 (+/-0.093) for {'C': 0.01, 'multi_class': 'ovr'}\n",
      "0.813 (+/-0.087) for {'C': 0.05, 'multi_class': 'ovr'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "============================================================\n",
    "Parameter estimation using grid search with cross-validation\n",
    "============================================================\n",
    "\n",
    "This examples shows how a classifier is optimized by cross-validation,\n",
    "which is done using the :class:`sklearn.model_selection.GridSearchCV` object\n",
    "\n",
    "More details on tools available for model selection can be found in the\n",
    "sections on :ref:`cross_validation` and :ref:`grid_search`.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import SCORERS\n",
    "\n",
    "print(__doc__)\n",
    "\n",
    "X = fvs_train\n",
    "y = true_label_train.flatten()\n",
    "\n",
    "# Set the parameters by cross-validation\n",
    "tuned_parameters = [{'C': [0.0001, 0.001, 0.005, 0.01, 0.05], 'multi_class': [\"ovr\"]}]\n",
    "\n",
    "scores = ['precision', 'recall']\n",
    "\n",
    "for score in scores:\n",
    "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "    print()\n",
    "\n",
    "    clf = GridSearchCV(svm.LinearSVC(), tuned_parameters, cv=5, scoring='%s_micro' % score)\n",
    "    clf.fit(X, y)\n",
    "\n",
    "    print(\"Best parameters set found on training set:\")\n",
    "    print()\n",
    "    print(clf.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on training set:\")\n",
    "    print()\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score use dev data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=0.005, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "clf_f = svm.LinearSVC(multi_class=\"ovr\",C=clf.best_params_['C'])\n",
    "clf_f.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full training set.\n",
      "The scores are computed on the full validation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.33      0.60      0.43         5\n",
      "         1.0       0.22      0.40      0.29         5\n",
      "         2.0       0.67      0.40      0.50         5\n",
      "         3.0       0.40      0.40      0.40         5\n",
      "         4.0       0.40      0.40      0.40         5\n",
      "         5.0       0.20      0.20      0.20         5\n",
      "         6.0       0.29      0.40      0.33         5\n",
      "         7.0       0.00      0.00      0.00         5\n",
      "         8.0       0.25      0.40      0.31         5\n",
      "         9.0       0.25      0.20      0.22         5\n",
      "        10.0       0.50      0.80      0.62         5\n",
      "        11.0       0.80      0.80      0.80         5\n",
      "        12.0       0.00      0.00      0.00         5\n",
      "        13.0       0.50      0.40      0.44         5\n",
      "        14.0       0.67      0.80      0.73         5\n",
      "        15.0       0.67      0.40      0.50         5\n",
      "        16.0       0.50      0.40      0.44         5\n",
      "        17.0       0.50      0.40      0.44         5\n",
      "        18.0       0.50      0.40      0.44         5\n",
      "        19.0       0.00      0.00      0.00         5\n",
      "        20.0       0.40      0.80      0.53         5\n",
      "        21.0       0.71      1.00      0.83         5\n",
      "        22.0       1.00      0.80      0.89         5\n",
      "        23.0       0.33      0.20      0.25         5\n",
      "        24.0       0.75      0.60      0.67         5\n",
      "\n",
      "   micro avg       0.45      0.45      0.45       125\n",
      "   macro avg       0.43      0.45      0.43       125\n",
      "weighted avg       0.43      0.45      0.43       125\n",
      "\n",
      "\n",
      "The accuracy for the validation set:\n",
      "\n",
      "0.448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhshang/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(\"Detailed classification report:\")\n",
    "print()\n",
    "print(\"The model is trained on the full training set.\")\n",
    "print(\"The scores are computed on the full validation set.\")\n",
    "print()\n",
    "y_true, y_pred = true_label_dev.flatten(), clf.predict(fvs_dev)\n",
    "print(classification_report(y_true, y_pred))\n",
    "print()\n",
    "acc = accuracy_score(y_true, y_pred)\n",
    "print(\"The accuracy for the validation set:\")\n",
    "print()\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full training set.\n",
      "The scores are computed on the full test set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.57      0.80      0.67         5\n",
      "         1.0       0.67      0.40      0.50         5\n",
      "         2.0       0.67      0.40      0.50         5\n",
      "         3.0       0.43      0.60      0.50         5\n",
      "         4.0       1.00      0.40      0.57         5\n",
      "         5.0       0.67      0.40      0.50         5\n",
      "         6.0       0.20      0.20      0.20         5\n",
      "         7.0       0.33      0.20      0.25         5\n",
      "         8.0       0.38      0.60      0.46         5\n",
      "         9.0       0.14      0.20      0.17         5\n",
      "        10.0       0.67      0.80      0.73         5\n",
      "        11.0       0.80      0.80      0.80         5\n",
      "        12.0       0.25      0.20      0.22         5\n",
      "        13.0       0.71      1.00      0.83         5\n",
      "        14.0       0.60      0.60      0.60         5\n",
      "        15.0       0.67      0.80      0.73         5\n",
      "        16.0       0.33      0.20      0.25         5\n",
      "        17.0       0.75      0.60      0.67         5\n",
      "        18.0       0.50      0.40      0.44         5\n",
      "        19.0       0.67      0.40      0.50         5\n",
      "        20.0       0.67      0.40      0.50         5\n",
      "        21.0       0.56      1.00      0.71         5\n",
      "        22.0       0.83      1.00      0.91         5\n",
      "        23.0       0.33      0.60      0.43         5\n",
      "        24.0       0.67      0.40      0.50         5\n",
      "\n",
      "   micro avg       0.54      0.54      0.54       125\n",
      "   macro avg       0.56      0.54      0.53       125\n",
      "weighted avg       0.56      0.54      0.53       125\n",
      "\n",
      "\n",
      "The accuracy for the test set:\n",
      "\n",
      "0.536\n"
     ]
    }
   ],
   "source": [
    "print(\"Detailed classification report:\")\n",
    "print()\n",
    "print(\"The model is trained on the full training set.\")\n",
    "print(\"The scores are computed on the full test set.\")\n",
    "print()\n",
    "y_true_svm, y_pred_svm = true_label_test.flatten(), clf.predict(fvs_test)\n",
    "print(classification_report(y_true_svm, y_pred_svm))\n",
    "print()\n",
    "acc = accuracy_score(y_true_svm, y_pred_svm)\n",
    "print(\"The accuracy for the test set:\")\n",
    "print()\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier-baseline random guess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(100)\n",
    "y_true = true_label_test.flatten()\n",
    "y_pred = y_true.copy()\n",
    "np.random.shuffle(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full training set.\n",
      "The scores are computed on the full test set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         5\n",
      "         1.0       0.00      0.00      0.00         5\n",
      "         2.0       0.00      0.00      0.00         5\n",
      "         3.0       0.00      0.00      0.00         5\n",
      "         4.0       0.00      0.00      0.00         5\n",
      "         5.0       0.00      0.00      0.00         5\n",
      "         6.0       0.00      0.00      0.00         5\n",
      "         7.0       0.00      0.00      0.00         5\n",
      "         8.0       0.20      0.20      0.20         5\n",
      "         9.0       0.00      0.00      0.00         5\n",
      "        10.0       0.40      0.40      0.40         5\n",
      "        11.0       0.00      0.00      0.00         5\n",
      "        12.0       0.00      0.00      0.00         5\n",
      "        13.0       0.00      0.00      0.00         5\n",
      "        14.0       0.00      0.00      0.00         5\n",
      "        15.0       0.00      0.00      0.00         5\n",
      "        16.0       0.20      0.20      0.20         5\n",
      "        17.0       0.00      0.00      0.00         5\n",
      "        18.0       0.20      0.20      0.20         5\n",
      "        19.0       0.00      0.00      0.00         5\n",
      "        20.0       0.00      0.00      0.00         5\n",
      "        21.0       0.00      0.00      0.00         5\n",
      "        22.0       0.20      0.20      0.20         5\n",
      "        23.0       0.00      0.00      0.00         5\n",
      "        24.0       0.00      0.00      0.00         5\n",
      "\n",
      "   micro avg       0.05      0.05      0.05       125\n",
      "   macro avg       0.05      0.05      0.05       125\n",
      "weighted avg       0.05      0.05      0.05       125\n",
      "\n",
      "\n",
      "The accuracy for the test set:\n",
      "\n",
      "0.048\n"
     ]
    }
   ],
   "source": [
    "print(\"Detailed classification report:\")\n",
    "print()\n",
    "print(\"The model is trained on the full training set.\")\n",
    "print(\"The scores are computed on the full test set.\")\n",
    "print()\n",
    "print(classification_report(y_true, y_pred))\n",
    "print()\n",
    "acc = accuracy_score(y_true, y_pred)\n",
    "print(\"The accuracy for the test set:\")\n",
    "print()\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reviewer analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Single author word proportion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_f1_score = sklearn.metrics.f1_score(y_true_svm, y_pred_svm, average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_word_portion = reviewers_literature_single_multiple_author_word_count[:,0] / np.sum(reviewers_literature_single_multiple_author_word_count,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(single_word_portion, svm_f1_score, '.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SpearmanrResult(correlation=-0.1227739100639645, pvalue=0.5587758434122012)"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scipy.stats.spearmanr(single_word_portion, svm_f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_lit_texts = [' '.join(sublib) for sublib in reviewers_literature]\n",
    "#for texts in all_lit_texts:\n",
    "#    print(len(nltk.word_tokenize(texts)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "total number of words in training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAFUxJREFUeJzt3X+MHOd93/H3V0fTjm3FoslzoJIUfxSsEaY1LHNBUXVRqIkdU0pANk3Rko4BqwlDNDGdH07bSHCgKiyKuErQ2EHYxoSgOglk04qbJqxBl01dBU3TUOZdLNmmZNoXWjRPdKOLzNhAg5Y689s/diivVkve3N3s7eyj9wtYcObZ52a/uxx+bvjMzD6RmUiSynLDqAuQJDXPcJekAhnuklQgw12SCmS4S1KBDHdJKpDhLkkFMtwlqUCGuyQVaNWoXnjdunW5efPmUb28JI2l6enpv8jMyYX6jSzcN2/ezNTU1KheXpLGUkScr9PPYRlJKpDhLkkFMtwlqUCGuyQVyHCXpAIZ7pJUIMNd0oKmz1/iyKMzTJ+/NOpSVFOt69wjYjfwIWACeDAzP9D3/CbgIWAS+DrwrsycbbhWSSMwff4SP/LgKS7PX2H1qht4+MAudmxaM+qytIAFj9wjYgI4AtwJbAf2R8T2vm6/AvxWZr4JOAz8UtOFShqNU+ee4/L8Fa4kPD9/hVPnnht1SaqhzrDMTmAmM89l5mXgGLC3r8924NPV8qMDnpc0pnZtXcvqVTcwEfCKVTewa+vaUZekGuoMy6wHLvSszwK39fV5AvhhukM3PwTcGBFrM9Nf8dKY27FpDQ8f2MWpc8+xa+tah2TGRJ1wjwFt2bf+z4Bfj4i7gf8BPAPMv2RDEQeBgwC33HLLogqVNDo7Nq0x1MdMnWGZWWBjz/oG4GJvh8y8mJn/IDNvBd5ftX2jf0OZeTQzO5nZmZxc8EvNJElLVCfcTwPbImJLRKwG9gHHeztExLqIuLqte+leOSNJGpEFwz0z54FDwEngKeCRzDwTEYcjYk/V7Q7gbER8Cfgu4F8PqV5JUg2R2T98vjI6nU76fe6StDgRMZ2ZnYX6eYeqJBXIcJekAhnuklQgw12SCmS4S1KBDHdJKpDhLkkFMtwlqUCGuyQVyHCXpAIZ7pJGxrlZh6fWHKqS1DTnZh0uj9wljYRzsw6X4S5pJJybdbgclpE0Es7NOlyGu6SRcW7W4XFYRpIKZLhLUoFqhXtE7I6IsxExExH3DHj+loh4NCI+GxGfi4i7mi9VklTXguEeERPAEeBOYDuwPyK293X7BboTZ98K7AP+XdOFSm3jDThqszonVHcCM5l5DiAijgF7gSd7+iTwndXy64CLTRYptY034Kjt6gzLrAcu9KzPVm297gfeFRGzwAngvYM2FBEHI2IqIqbm5uaWUK7UDt6Ao7arE+4xoC371vcDH8nMDcBdwG9HxEu2nZlHM7OTmZ3JycnFVyu1hDfgqO3qDMvMAht71jfw0mGXHwN2A2Tmn0TEq4B1wLNNFCm1jTfgqO3qhPtpYFtEbAGeoXvC9J19fb4KfB/wkYj4buBVgOMuKpo34KjNFhyWycx54BBwEniK7lUxZyLicETsqbr9HPDjEfEE8DHg7szsH7qRJK2QWl8/kJkn6J4o7W27r2f5SeCtzZYmSVoq71CVpAIZ7pJUIMNdkgpkuEtSgQx3SSqQ4S5JBTLcJalAhrskFchwl6QCGe6SVCDDXZIKZLhLUoEM9zEzrHk7nQ9UKkutb4VUOwxr3k7nA5XK45H7GBnWvJ3OByqVx3AfI8Oat9P5QKWVs1JDoDGqCZM6nU5OTU2N5LXH2fT5S0OZt3NY25X0bU0MgUbEdGZ2FupXa8w9InYDHwImgAcz8wN9z/8q8Peq1VcDb8jMmxZVsWoZ1rydzgcqDd+gIdBh/btbMNwjYgI4ArwdmAVOR8Txamo9ADLzZ3v6vxe4dQi1StJYuzoE+vz8laEPgdY5ct8JzGTmOYCIOAbsBZ68Rv/9wL9spjxJKseOTWt4+MCuFRkCrRPu64ELPeuzwG2DOkbEJmAL8N+XX5oklWelhkDrXC0TA9qudRZ2H/CJzPzWwA1FHIyIqYiYmpubq1ujJGmR6oT7LLCxZ30DcPEaffcBH7vWhjLzaGZ2MrMzOTlZv0pJ0qLUCffTwLaI2BIRq+kG+PH+ThHxRmAN8CfNlihJWqwFwz0z54FDwEngKeCRzDwTEYcjYk9P1/3AsRzVhfOSpBfUus49M08AJ/ra7utbv7+5siRJy+HXD0hSgQx3SSqQ4f4y4He1j4afu0bJ73MvnN/VPhp+7ho1j9wL53e1j4afu0bNcC+c39U+Gn7uGjW/z/1lwO9qHw0/dw1Do9/nrvHmd7WPhp+7RslhGUkqkOEuSQUy3CWpQIa7JBXIcJekAhnuklQgw12SCmS4S1KBDHdJKpDhLkkFqhXuEbE7Is5GxExE3HONPv8oIp6MiDMR8dFmy5QkLcaC3y0TERPAEeDtwCxwOiKOZ+aTPX22AfcCb83MSxHxhmEVLElaWJ0j953ATGaey8zLwDFgb1+fHweOZOYlgMx8ttkypeFwtiSVqs63Qq4HLvSszwK39fX5GwAR8cfABHB/Zv6XRiqUhsTZklSyOkfuMaCt/0vgVwHbgDuA/cCDEXHTSzYUcTAipiJiam5ubrG1So1ytiSVrE64zwIbe9Y3ABcH9Pn9zHw+M78CnKUb9i+SmUczs5OZncnJyaXWLDXC2ZJUsjrDMqeBbRGxBXgG2Ae8s6/P79E9Yv9IRKyjO0xzrslCpabt2LSGhw/scrYkFWnBcM/M+Yg4BJykO57+UGaeiYjDwFRmHq+e+/6IeBL4FvDPM9P/46r1nC1JpXIOVUkaI3XnUPUOVWmIvNRSo+IE2dKQeKmlRskjd2lIvNRSo2S4S0PipZYaJYdlpCHxUkuNkuEuDZGXWmpUHJaRpAIZ7pJUIMNdkgpkuEtSgQx3SSqQ4S5JBTLcJalAhrskFchwl6QCGe6SVCDDXZIKZLhLUoFqhXtE7I6IsxExExH3DHj+7oiYi4jHq8eB5kuVJNW1YLhHxARwBLgT2A7sj4jtA7p+PDPfXD0ebLhONWwlpn9r+jWWs72Sprtr4r20ZRsanjpf+bsTmMnMcwARcQzYCzw5zMI0PCsx/VvTr7Gc7ZU03V0T76Ut29Bw1RmWWQ9c6Fmfrdr6/XBEfC4iPhERGwdtKCIORsRUREzNzc0toVw1YSWmf2v6NZazvZKmu2vivbRlGxquOuEeA9qyb/0/A5sz803AfwN+c9CGMvNoZnYyszM5Obm4StWYlZj+renXWM72Spruron30pZtaLgisz+n+zpE3A7cn5nvqNbvBcjMX7pG/wng65n5uuttt9Pp5NTU1JKK1vJNn7809Onfmn6N5WxvJd7vSmnivbRlG1q8iJjOzM6C/WqE+yrgS8D3Ac8Ap4F3ZuaZnj43Z+bXquUfAn4+M3ddb7uGuyQtXt1wX/CEambOR8Qh4CQwATyUmWci4jAwlZnHgZ+KiD3APPB14O5lVS9JWpYFj9yHxSN3SVq8ukfu3qEqSQUy3CWpQIa71Mc7L1WCOneoSi8b3nmpUnjkLvXwzkuVwnCXenjnpUrhsIzUY8emNTx8YJd3XmrsGe5qlTbc0r5j0xpDXWPPcFdreDJTao5j7moNT2ZKzTHc1RqezJSa47CMGrfUcXNPZkrNMdzVqOWOm3syU2qGwzJqlOPmUjsY7mqU4+ZSOzgso0Y5bi61g+GuxjluLo1erWGZiNgdEWcjYiYi7rlOv38YERkRC84SIkkangXDPSImgCPAncB2YH9EbB/Q70bgp4DHmi5SkrQ4dY7cdwIzmXkuMy8Dx4C9A/r9K+AB4P82WJ8kaQnqhPt64ELP+mzV9oKIuBXYmJmfbLA2SdIS1Qn3GNCWLzwZcQPwq8DPLbihiIMRMRURU3Nzc/WrlCQtSp1wnwU29qxvAC72rN8I/E3gDyPiaWAXcHzQSdXMPJqZnczsTE5OLr1qSdJ11Qn308C2iNgSEauBfcDxq09m5jcyc11mbs7MzcApYE9mTg2lYknSghYM98ycBw4BJ4GngEcy80xEHI6IPcMuUJK0eLVuYsrME8CJvrb7rtH3juWXJUlaDr9bRpIKZLhLUoEMd0kqkOEuSQUy3CWpQIa7JBXIcJekAhnuklQgw12SCmS4S1KBDHdJKpDhLkkFMtwlqUCGuyQVyHCXpAIZ7pJUIMNdkgpkuEtSgWqFe0TsjoizETETEfcMeP6fRsTnI+LxiPifEbG9+VIlSXUtGO4RMQEcAe4EtgP7B4T3RzPzb2Xmm4EHgH/beKWSpNrqHLnvBGYy81xmXgaOAXt7O2TmN3tWXwNkcyVKkhZrVY0+64ELPeuzwG39nSLiPcD7gNXA9w7aUEQcBA4C3HLLLYutVZJUU50j9xjQ9pIj88w8kpl/Hfh54BcGbSgzj2ZmJzM7k5OTi6tUklRbnXCfBTb2rG8ALl6n/zHg7y+nKEnS8tQJ99PAtojYEhGrgX3A8d4OEbGtZ/UHgC83V6IkabEWHHPPzPmIOAScBCaAhzLzTEQcBqYy8zhwKCLeBjwPXALePcyiJUnXV+eEKpl5AjjR13Zfz/JPN1yXJGkZvENVkgpkuEtSgQx3SSqQ4S5JBTLcJalAhrskFchwH3PT5y9x5NEZps9fGnUpQ1H6+5OGpdZ17mqn6fOX+JEHT3F5/gqrV93Awwd2sWPTmlGX1ZjS3580TB65j7FT557j8vwVriQ8P3+FU+eeG3VJjSr9/UnDZLiPsV1b17J61Q1MBLxi1Q3s2rp21CU1qvT3Jw1TZI5mXo1Op5NTU1Mjee2STJ+/xKlzz7Fr69oihyxKf3/SYkXEdGZ2FurnmPuY27FpTdGhV/r7k4bFYRlJKpDhPgJe3idp2ByWWWFe3idpJXjkvsK8vE/SSjDcV5iX90laCbWGZSJiN/AhutPsPZiZH+h7/n3AAWAemAN+NDPPN1xrEXZsWsPDB3Z5eZ+koVow3CNiAjgCvB2YBU5HxPHMfLKn22eBTmb+VUT8BPAA8I+HUXAJvLxP0rDVGZbZCcxk5rnMvAwcA/b2dsjMRzPzr6rVU8CGZsvUuPLKIGk06gzLrAcu9KzPArddp/+PAZ9aTlEqg1cGSaNT58g9BrQN/M6CiHgX0AF++RrPH4yIqYiYmpubq1+lxpJXBkmjUyfcZ4GNPesbgIv9nSLibcD7gT2Z+f8GbSgzj2ZmJzM7k5OTS6lXY8Qrg6TRqTMscxrYFhFbgGeAfcA7eztExK3Ah4Hdmfls41VqLHllkDQ6C4Z7Zs5HxCHgJN1LIR/KzDMRcRiYyszjdIdhXgv8TkQAfDUz9wyxbo0JrwySRqPWde6ZeQI40dd2X8/y2xquS5K0DN6hKkkFMtwlqUBjF+7eFCNJCxurr/z1phhJqmesjty9KUaS6hmrcPemGEmqZ6yGZbwpRpLqGatwB2+KkaQ6xmpYRpJUj+EuSQUy3CWpQIa7JBXIcJekAhnuklSgyBw4Y97wXzhiDjg/khevbx3wF6MuYpHGreZxqxeseSWMW72wcjVvyswFp7IbWbiPg4iYyszOqOtYjHGredzqBWteCeNWL7SvZodlJKlAhrskFchwv76joy5gCcat5nGrF6x5JYxbvdCymh1zl6QCeeQuSQUqPtwjYmNEPBoRT0XEmYj46ar99RHxBxHx5erPNVV7RMSvRcRMRHwuIt7Ss613V/2/HBHv7mnfERGfr37m1yIillnzqyLiMxHxRFXzL1btWyLiser1Px4Rq6v2V1brM9Xzm3u2dW/VfjYi3tHTvrtqm4mIe5ZTb882JyLisxHxyTGp9+nq7+3xiJiq2lq7X1TbvCkiPhERX6z26dvbXHNEvLH6fK8+vhkRP9Pymn+2+nf3hYj4WHT/PbZ6Xx4oM4t+ADcDb6mWbwS+BGwHHgDuqdrvAf5NtXwX8CkggF3AY1X764Fz1Z9rquU11XOfAW6vfuZTwJ3LrDmA11bLrwAeq2p5BNhXtf8G8BPV8k8Cv1Et7wM+Xi1vB54AXglsAf4MmKgefwZsBVZXfbY38Fm/D/go8Mlqve31Pg2s62tr7X5RbfM3gQPV8mrgprbX3FP7BPC/gU1trRlYD3wF+I6effjutu/LA9/LMDba5gfw+8DbgbPAzVXbzcDZavnDwP6e/mer5/cDH+5p/3DVdjPwxZ72F/VroN5XA38K3Eb3BolVVfvtwMlq+SRwe7W8quoXwL3AvT3bOln93As/W7W/qN8S69wAfBr4XuCT1eu3tt5qO0/z0nBv7X4BfCfd4Ilxqbmvzu8H/rjNNdMN9wt0f4msqvbld7R9Xx70KH5Yplf1X6Zb6R4Jf1dmfg2g+vMNVberf7lXzVZt12ufHdC+3FonIuJx4FngD+j+tv/LzJwf8Dov1FY9/w1g7RLey3J8EPgXwJVqfW3L6wVI4L9GxHREHKza2rxfbAXmgP8Q3eGvByPiNS2vudc+4GPVcitrzsxngF8Bvgp8je6+OU379+WXeNmEe0S8FviPwM9k5jev13VAWy6hfVky81uZ+Wa6R8Q7ge++zuuMtOaI+EHg2cyc7m2+zmu04jMG3pqZbwHuBN4TEX/3On3bUPMq4C3Av8/MW4H/Q3dI41raUHO3kO4Y9R7gdxbqeo0aVmpfXgPspTuU8teA19DdP671Gq35jPu9LMI9Il5BN9gfzszfrZr/PCJurp6/me4RMnR/k27s+fENwMUF2jcMaG9EZv4l8Id0xx9vioirUyP2vs4LtVXPvw74+hLey1K9FdgTEU8Dx+gOzXywxfUCkJkXqz+fBf4T3V+ibd4vZoHZzHysWv8E3bBvc81X3Qn8aWb+ebXe1prfBnwlM+cy83ngd4G/Tcv35YGGMdbTpgfd35S/BXywr/2XefEJnQeq5R/gxSd0PlO1v57ueOea6vEV4PXVc6ervldP6Ny1zJongZuq5e8A/gj4QbpHPb0ndX6yWn4PLz6p80i1/D28+KTOObondFZVy1v49kmd72no876Db59QbW29dI/IbuxZ/l/A7jbvF9U2/wh4Y7V8f1Vvq2uutnsM+Cdt//dH99zWGbrnuoLuCez3tnlfvuZ7GcZG2/QA/g7d//Z8Dni8etxFd1zs08CXqz+v7igBHKE7xv15oNOzrR8FZqpH747aAb5Q/cyv03fCawk1vwn4bFXzF4D7qvatdK8MmKl2tldW7a+q1meq57f2bOv9VV1n6bmKoPoMvlQ99/4GP+87+Ha4t7beqrYnqseZq9ts835RbfPNwFS1b/we3aBre82vBp4DXtfT1tqagV8Evlht87fpBnRr9+VrPbxDVZIK9LIYc5eklxvDXZIKZLhLUoEMd0kqkOEuSQUy3CWpQIa7JBXIcJekAv1/P1HDMlUCokoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(np.sum(reviewers_literature_single_multiple_author_word_count,axis=1), svm_f1_score, '.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "x = np.sum(reviewers_literature_single_multiple_author_word_count,axis=1)\n",
    "y = svm_f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SpearmanrResult(correlation=0.4737757646353846, pvalue=0.016738357454073687)"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scipy.stats.spearmanr(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
