{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"leading_reviewer_data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "reviewer_path_list = glob(data_path+\"*/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only use 10 reviews for each reviewer (pick out the 10 largest size of reviews)\n",
    "reviewers = []\n",
    "reviewers_review = []\n",
    "reviewers_literature = []\n",
    "for reviewer_path in reviewer_path_list:\n",
    "    reviewers.append(re.search(r'leading_reviewer_data\\\\([a-zA-Z_-]*)\\\\',reviewer_path).group(1))\n",
    "    current_reviewer_review = [f for f in os.listdir(reviewer_path) if '.txt' in f]\n",
    "    # select the 10 largest size of reviews\n",
    "    current_selected_review_index = np.argsort([os.stat(reviewer_path+f).st_size for f in os.listdir(reviewer_path) if '.txt' in f])[::-1][:10]\n",
    "    current_reviewer_review_selected = list(np.array(current_reviewer_review)[ind])\n",
    "    # get the review texts\n",
    "    review_texts = []\n",
    "    for nm in current_reviewer_review_selected:\n",
    "        with open(reviewer_path+nm, encoding=\"utf8\") as f:\n",
    "            text_to_append = f.read().replace('\\n',' ')\n",
    "            review_texts.append(text_to_append)\n",
    "    reviewers_review.append(review_texts)\n",
    "    \n",
    "    current_reviewer_literature = [f for f in os.listdir(reviewer_path+\"training_data\\\\\") if '.txt' in f]\n",
    "    # get the literature texts\n",
    "    literature_texts = []\n",
    "    for nm in current_reviewer_literature:\n",
    "        with open(reviewer_path+\"training_data\\\\\"+nm, encoding=\"utf8\") as f:\n",
    "            text_to_append = f.read().replace('\\n',' ')\n",
    "            literature_texts.append(text_to_append)\n",
    "    reviewers_literature.append(literature_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build training set, development set and test set\n",
    "## Randomly picking the test data from the whole dataset\n",
    "total: 25 reviewers\n",
    "\n",
    "each reviewer has 10 reviews and 10 literatures.\n",
    "\n",
    "Test set: half of the reviews (each reviewer has 5 reviews)\n",
    "\n",
    "Development set: the other half of the reviews\n",
    "\n",
    "Training set: all the literatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(100)\n",
    "dev_set = []\n",
    "test_set = []\n",
    "for reviewer in reviewers_review:\n",
    "    # copy() is important here, or the reviewers_review will be shuffled\n",
    "    reviewer_cp = reviewer.copy()\n",
    "    np.random.shuffle(reviewer_cp)\n",
    "    dev_set.append(reviewer_cp[:5])\n",
    "    test_set.append(reviewer_cp[5:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lexical and punctuation features\n",
    "\n",
    "Lexical features:\n",
    "\n",
    "The average number of words per sentence\n",
    "\n",
    "Sentence length variation\n",
    "\n",
    "Lexical diversity, which is a measure of the richness of the authorâ€™s vocabulary\n",
    "\n",
    "Punctuation features:\n",
    "\n",
    "Average number of commas, semicolons and colons per sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create feature vectors\n",
    "def LexicalFeatures(reviews_texts):\n",
    "    \"\"\"\n",
    "    Compute feature vectors for word and punctuation features\n",
    "    \"\"\"\n",
    "    num_reviews = len(reviews_texts)\n",
    "    fvs_lexical = np.zeros((len(reviews_texts), 3), np.float64)\n",
    "    fvs_punct = np.zeros((len(reviews_texts), 3), np.float64)\n",
    "    for e, ch_text in enumerate(reviews_texts):\n",
    "        # note: the nltk.word_tokenize includes punctuation\n",
    "        tokens = nltk.word_tokenize(ch_text.lower())\n",
    "        words = word_tokenizer.tokenize(ch_text.lower())\n",
    "        sentences = sentence_tokenizer.tokenize(ch_text)\n",
    "        vocab = set(words)\n",
    "        words_per_sentence = np.array([len(word_tokenizer.tokenize(s))\n",
    "                                   for s in sentences])\n",
    " \n",
    "        # average number of words per sentence\n",
    "        fvs_lexical[e, 0] = words_per_sentence.mean()\n",
    "        # sentence length variation\n",
    "        fvs_lexical[e, 1] = words_per_sentence.std()\n",
    "        # Lexical diversity\n",
    "        fvs_lexical[e, 2] = len(vocab) / float(len(words))\n",
    " \n",
    "        # Commas per sentence\n",
    "        fvs_punct[e, 0] = tokens.count(',') / float(len(sentences))\n",
    "        # Semicolons per sentence\n",
    "        fvs_punct[e, 1] = tokens.count(';') / float(len(sentences))\n",
    "        # Colons per sentence\n",
    "        fvs_punct[e, 2] = tokens.count(':') / float(len(sentences))\n",
    "\n",
    "    # apply whitening to decorrelate the features\n",
    "    fvs_lexical = whiten(fvs_lexical)\n",
    "    fvs_punct = whiten(fvs_punct)\n",
    "    \n",
    "    return fvs_lexical, fvs_punct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## bag of words feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "bag of words feature needs to build the corpus from training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 763,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_training_texts = [' '.join(sublib) for sublib in reviewers_literature]\n",
    "all_training_texts = ' '.join(all_training_texts)\n",
    "all_tokens = nltk.word_tokenize(all_training_texts)\n",
    "# get rid of punctuations or other special markers\n",
    "all_tokens = [token.lower() for token in all_tokens if token.isalpha()]\n",
    "\n",
    "# word_to_ix maps each word in the vocab to a unique integer, which will be its index into the Bag of words vector\n",
    "word_to_ix = {}\n",
    "for word in all_tokens:\n",
    "    if word not in word_to_ix:\n",
    "        word_to_ix[word] = len(word_to_ix)\n",
    "        \n",
    "VOCAB_SIZE = len(word_to_ix)\n",
    "\n",
    "NUM_TOP_WORDS = 20\n",
    "# get most common words in the whole training set\n",
    "fdist = nltk.FreqDist(all_tokens)\n",
    "vocab_top = fdist.most_common(NUM_TOP_WORDS)\n",
    "vocab_selected = [word_to_ix[voc[0]] for voc in vocab_top]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 764,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the input_text can only be one literature\n",
    "def BagOfWords(input_text, word_to_ix, vocab_selected):\n",
    "    \"\"\"\n",
    "    Compute the bag of words feature vectors, based on the most common words\n",
    "     in the whole training set\n",
    "    \"\"\"\n",
    "    vec = torch.zeros(len(word_to_ix))\n",
    "    tokens = nltk.word_tokenize(input_text)\n",
    "    # get rid of punctuations or other special markers\n",
    "    tokens = [token.lower() for token in tokens if token.isalpha()]\n",
    "    for word in tokens:\n",
    "        if word in word_to_ix:\n",
    "            vec[word_to_ix[word]] += 1\n",
    "    # the bag of word vector\n",
    "    vec = vec.view(1, -1)\n",
    "    # the bow vector for the selected top words\n",
    "    fvs_bow = torch.index_select(vec,1,torch.tensor(vocab_selected))\n",
    "    fvs_bow /= torch.sum(vec)\n",
    "    return fvs_bow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Syntactic features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 765,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SyntacticFeatures(reviews_texts):\n",
    "    \"\"\"\n",
    "    Extract feature vector for part of speech frequencies\n",
    "    \"\"\"\n",
    "    # get part of speech for each token in each review\n",
    "    def token_to_pos(ch):\n",
    "        tokens = nltk.word_tokenize(ch)\n",
    "        return [p[1] for p in nltk.pos_tag(tokens)]\n",
    "    review_pos = [token_to_pos(ch) for ch in reviews_texts]\n",
    " \n",
    "    # count frequencies for common POS types\n",
    "    pos_list = ['NN', 'NNP', 'DT', 'IN', 'JJ', 'NNS']\n",
    "    fvs_syntax = np.array([[ch.count(pos) for pos in pos_list] for ch in review_pos]).astype(np.float64)\n",
    " \n",
    "    # normalise by dividing each row by number of tokens in the review\n",
    "    fvs_syntax /= np.c_[np.array([len(ch) for ch in review_pos])]\n",
    "    \n",
    "    return fvs_syntax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline: logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 766,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from scipy.cluster.vq import whiten\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "sentence_tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "word_tokenizer = nltk.tokenize.RegexpTokenizer(r'\\w+')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 767,
   "metadata": {},
   "outputs": [],
   "source": [
    "fvs_lexical_train = np.array([], dtype=np.int64).reshape(0,3)\n",
    "fvs_punct_train = np.array([], dtype=np.int64).reshape(0,3)\n",
    "fvs_bow_train = np.array([], dtype=np.int64).reshape(0,NUM_TOP_WORDS)\n",
    "fvs_syntax_train = np.array([], dtype=np.int64).reshape(0,6)\n",
    "true_label_train = np.array([], dtype=np.int64).reshape(0,1)\n",
    "for lit in np.arange(len(reviewers_literature)):\n",
    "    # lexical and punct\n",
    "    fvs_lexical_train_cur, fvs_punct_train_cur = LexicalFeatures(reviewers_literature[lit])\n",
    "    fvs_lexical_train = np.concatenate((fvs_lexical_train,fvs_lexical_train_cur))\n",
    "    fvs_punct_train = np.concatenate((fvs_punct_train,fvs_punct_train_cur))\n",
    "    # bag of words\n",
    "    for per_lit in reviewers_literature[lit]:\n",
    "        fvs_bow_train_cur = BagOfWords(per_lit, word_to_ix, vocab_selected)\n",
    "        fvs_bow_train = np.concatenate((fvs_bow_train,fvs_bow_train_cur))\n",
    "    # syntax\n",
    "    fvs_syntax_train_cur = SyntacticFeatures(reviewers_literature[lit])\n",
    "    fvs_syntax_train = np.concatenate((fvs_syntax_train,fvs_syntax_train_cur))\n",
    "    # label\n",
    "    true_label_train = np.concatenate((true_label_train, lit*np.ones(( len(reviewers_literature[lit]) ,1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 768,
   "metadata": {},
   "outputs": [],
   "source": [
    "fvs_train = np.concatenate((fvs_bow_train,fvs_syntax_train),axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 769,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "\n",
    "torch.manual_seed(100)\n",
    "cuda = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 770,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LRClassifier(nn.Module):  # inheriting from nn.Module!\n",
    "\n",
    "    def __init__(self, input_size, num_labels):\n",
    "        # calls the init function of nn.Module.  Dont get confused by syntax,\n",
    "        # just always do it in an nn.Module\n",
    "        super(LRClassifier, self).__init__()\n",
    "\n",
    "        # Define the parameters that you will need.  In this case, we need A and b,\n",
    "        # the parameters of the affine mapping.\n",
    "        # Torch defines nn.Linear(), which provides the affine map.\n",
    "        # Make sure you understand why the input dimension is fvs_dim\n",
    "        # and the output is num_labels!\n",
    "        self.linear = nn.Linear(input_size, num_labels)\n",
    "\n",
    "        # NOTE! The non-linearity log softmax does not have parameters! So we don't need\n",
    "        # to worry about that here\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Pass the input through the linear layer,\n",
    "        # then pass that through log_softmax.\n",
    "        # Many non-linearities and other functions are in torch.nn.functional\n",
    "        out = self.linear(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 783,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1/500], Loss: 3.2290\n",
      "Epoch: [51/500], Loss: 3.1808\n",
      "Epoch: [101/500], Loss: 3.1401\n",
      "Epoch: [151/500], Loss: 3.0998\n",
      "Epoch: [201/500], Loss: 3.0603\n",
      "Epoch: [251/500], Loss: 3.0217\n",
      "Epoch: [301/500], Loss: 2.9841\n",
      "Epoch: [351/500], Loss: 2.9474\n",
      "Epoch: [401/500], Loss: 2.9116\n",
      "Epoch: [451/500], Loss: 2.8767\n"
     ]
    }
   ],
   "source": [
    "NUM_LABELS = len(reviewers_literature)\n",
    "INPUT_SIZE = fvs_train.shape[1]\n",
    "input_vector = torch.from_numpy(fvs_train)\n",
    "input_vector = input_vector.float()\n",
    "input_vector = input_vector.to(cuda)\n",
    "labels = torch.from_numpy(true_label_train)\n",
    "labels = labels.view(-1)\n",
    "labels = labels.long()\n",
    "labels = labels.to(cuda)\n",
    "model = LRClassifier(INPUT_SIZE, NUM_LABELS)\n",
    "model = model.to(cuda)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "num_epochs = 500\n",
    "\n",
    "# Training the Model\n",
    "for epoch in range(num_epochs):    \n",
    "    # Forward + Backward + Optimize\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(input_vector)\n",
    "    loss = criterion(outputs, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "        \n",
    "    if epoch % 50 == 0:\n",
    "        print ('Epoch: [%d/%d], Loss: %.4f' %(epoch+1, num_epochs, loss.data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### development data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 772,
   "metadata": {},
   "outputs": [],
   "source": [
    "fvs_lexical_dev = np.array([], dtype=np.int64).reshape(0,3)\n",
    "fvs_punct_dev = np.array([], dtype=np.int64).reshape(0,3)\n",
    "fvs_bow_dev = np.array([], dtype=np.int64).reshape(0,NUM_TOP_WORDS)\n",
    "fvs_syntax_dev = np.array([], dtype=np.int64).reshape(0,6)\n",
    "true_label_dev = np.array([], dtype=np.int64).reshape(0,1)\n",
    "for index in np.arange(len(dev_set)):\n",
    "    # lexical and punct\n",
    "    fvs_lexical_dev_cur, fvs_punct_dev_cur = LexicalFeatures(dev_set[index])\n",
    "    fvs_lexical_dev = np.concatenate((fvs_lexical_dev,fvs_lexical_dev_cur))\n",
    "    fvs_punct_dev = np.concatenate((fvs_punct_dev,fvs_punct_dev_cur))\n",
    "    # bag of words\n",
    "    for per_review in dev_set[index]:\n",
    "        fvs_bow_dev_cur = BagOfWords(per_review, word_to_ix, vocab_selected)\n",
    "        fvs_bow_dev = np.concatenate((fvs_bow_dev,fvs_bow_dev_cur))\n",
    "    # syntax\n",
    "    fvs_syntax_dev_cur = SyntacticFeatures(dev_set[index])\n",
    "    fvs_syntax_dev = np.concatenate((fvs_syntax_dev,fvs_syntax_dev_cur))\n",
    "    # label\n",
    "    true_label_dev = np.concatenate((true_label_dev, index*np.ones(( len(dev_set[index]) ,1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 773,
   "metadata": {},
   "outputs": [],
   "source": [
    "fvs_dev = np.concatenate((fvs_bow_dev,fvs_syntax_dev),axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score use dev data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 784,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on the 125 development sets: 24.000000 %\n"
     ]
    }
   ],
   "source": [
    "input_vector = torch.from_numpy(fvs_dev)\n",
    "input_vector = input_vector.float()\n",
    "input_vector = input_vector.to(cuda)\n",
    "labels = torch.from_numpy(true_label_dev)\n",
    "labels = labels.view(-1)\n",
    "labels = labels.long()\n",
    "labels = labels.to(cuda)\n",
    "\n",
    "# Test the Model\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "outputs = model(input_vector)\n",
    "_, predicted = torch.max(outputs.data, 1)\n",
    "total += labels.size(0)\n",
    "correct += (predicted == labels).sum()\n",
    "    \n",
    "print('Accuracy of the model on the %d development sets: %f %%' % (total , 100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test data and score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 786,
   "metadata": {},
   "outputs": [],
   "source": [
    "fvs_lexical_test = np.array([], dtype=np.int64).reshape(0,3)\n",
    "fvs_punct_test = np.array([], dtype=np.int64).reshape(0,3)\n",
    "fvs_bow_test = np.array([], dtype=np.int64).reshape(0,NUM_TOP_WORDS)\n",
    "fvs_syntax_test = np.array([], dtype=np.int64).reshape(0,6)\n",
    "true_label_test = np.array([], dtype=np.int64).reshape(0,1)\n",
    "for index in np.arange(len(test_set)):\n",
    "    # lexical and punct\n",
    "    fvs_lexical_test_cur, fvs_punct_test_cur = LexicalFeatures(test_set[index])\n",
    "    fvs_lexical_test = np.concatenate((fvs_lexical_test,fvs_lexical_test_cur))\n",
    "    fvs_punct_test = np.concatenate((fvs_punct_test,fvs_punct_test_cur))\n",
    "    # bag of words\n",
    "    for per_review in test_set[index]:\n",
    "        fvs_bow_test_cur = BagOfWords(per_review, word_to_ix, vocab_selected)\n",
    "        fvs_bow_test = np.concatenate((fvs_bow_test,fvs_bow_test_cur))\n",
    "    # syntax\n",
    "    fvs_syntax_test_cur = SyntacticFeatures(test_set[index])\n",
    "    fvs_syntax_test = np.concatenate((fvs_syntax_test,fvs_syntax_test_cur))\n",
    "    # label\n",
    "    true_label_test = np.concatenate((true_label_test, index*np.ones(( len(test_set[index]) ,1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 787,
   "metadata": {},
   "outputs": [],
   "source": [
    "fvs_test = np.concatenate((fvs_bow_test,fvs_syntax_test),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 795,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on the 125 test sets: 20.000000 %\n"
     ]
    }
   ],
   "source": [
    "input_vector = torch.from_numpy(fvs_test)\n",
    "input_vector = input_vector.float()\n",
    "input_vector = input_vector.to(cuda)\n",
    "labels = torch.from_numpy(true_label_test)\n",
    "labels = labels.view(-1)\n",
    "labels = labels.long()\n",
    "labels = labels.to(cuda)\n",
    "\n",
    "# Test the Model\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "outputs = model(input_vector)\n",
    "_, predicted = torch.max(outputs.data, 1)\n",
    "total += labels.size(0)\n",
    "correct += (predicted == labels).sum()\n",
    "print('Accuracy of the model on the %d test sets: %f %%' % (total , 100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
